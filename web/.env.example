# ===========================================
# REACT FRONTEND ENVIRONMENT CONFIGURATION
# ===========================================

# API Configuration
# Base URL for the Go backend API
VITE_API_BASE_URL=http://localhost:8084/api
# WebSocket URL for real-time communication
VITE_WEBSOCKET_URL=ws://localhost:8084/api/v1/chat/stream

# LLM Provider Configuration
# Default LLM provider to use: 'ollama' or 'bedrock'
VITE_DEFAULT_LLM_PROVIDER=ollama
# Default model to use
VITE_DEFAULT_MODEL=qwen2.5:1.5b

# Available Models for UI (comma-separated)
# Models available through Ollama
VITE_OLLAMA_MODELS=qwen2.5:1.5b,cogito:8b,gemma3:1b,qwen3:0.6b
# Models available through AWS Bedrock
VITE_BEDROCK_MODELS=anthropic.claude-3-5-sonnet-20241022-v2:0,anthropic.claude-3-haiku-20240307-v1:0,anthropic.claude-3-opus-20240229-v1:0

# Development Configuration
# Enable development mode features
VITE_DEV_MODE=true
# Log level for debugging: 'debug', 'info', 'warn', 'error'
VITE_LOG_LEVEL=debug
